# ğŸ FastAPI IoT Sensors API

A production-ready REST API for managing IoT sensors and their data, built with FastAPI and PostgreSQL without ORM, using the Repository Pattern.

## ğŸ“‹ Features

- âœ… Complete CRUD operations for Units, Sensors, and Sensor Data
- âœ… Repository Pattern (without ORM)
- âœ… Raw SQL queries with asyncpg
- âœ… Database migrations with Alembic
- âœ… Comprehensive unit tests with pytest
- âœ… Docker containerization with sample data initialization
- âœ… Clean architecture (layers: API â†’ Service â†’ Repository)
- âœ… SOLID principles implementation
- âœ… Type hints and Pydantic validation
- âœ… Statistics and aggregation endpoints
- âœ… Custom exception handling
- âœ… Comprehensive logging
- âœ… OpenAPI/Swagger documentation

## ğŸ—ï¸ Project Structure

```
FastAPI-Backend-Challenge-CRUD/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                          # API endpoints (routes)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ units.py                  # Unit endpoints
â”‚   â”‚   â”œâ”€â”€ sensors.py                # Sensor endpoints
â”‚   â”‚   â””â”€â”€ sensor_data.py            # Sensor data endpoints
â”‚   â”œâ”€â”€ models/                       # Pydantic models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ unit.py                   # Unit models
â”‚   â”‚   â”œâ”€â”€ sensor.py                 # Sensor models (with enums)
â”‚   â”‚   â””â”€â”€ sensor_data.py            # Sensor data models
â”‚   â”œâ”€â”€ repositories/                 # Data access layer (Repository Pattern)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                   # Base repository with common methods
â”‚   â”‚   â”œâ”€â”€ unit_repository.py        # Unit data access
â”‚   â”‚   â”œâ”€â”€ sensor_repository.py      # Sensor data access
â”‚   â”‚   â””â”€â”€ sensor_data_repository.py # Sensor data access
â”‚   â”œâ”€â”€ services/                     # Business logic layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ unit_service.py           # Unit business logic
â”‚   â”‚   â”œâ”€â”€ sensor_service.py         # Sensor business logic
â”‚   â”‚   â””â”€â”€ sensor_data_service.py    # Sensor data business logic
â”‚   â”œâ”€â”€ schemas/                      # API schemas and examples
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ api_examples.py           # OpenAPI examples and descriptions
â”‚   â”œâ”€â”€ database/                     # Database connection
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ connection.py             # Database pool management
â”‚   â”œâ”€â”€ exceptions/                   # Custom exceptions
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                     # Application configuration
â”‚   â””â”€â”€ main.py                       # FastAPI application setup
â”œâ”€â”€ alembic/                          # Database migrations
â”‚   â”œâ”€â”€ versions/                     # Migration files
â”‚   â”‚   â””â”€â”€ xxxx_initial_migration.py
â”‚   â”œâ”€â”€ env.py                        # Alembic environment
â”‚   â””â”€â”€ script.py.mako                # Migration template
â”œâ”€â”€ scripts/                          # Utility scripts
â”‚   â””â”€â”€ init_sample_data.py           # Sample data initialization
â”œâ”€â”€ tests/                            # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                   # Test fixtures
â”‚   â”œâ”€â”€ test_units.py                 # Unit endpoint tests
â”‚   â”œâ”€â”€ test_sensors.py               # Sensor endpoint tests
â”‚   â””â”€â”€ test_sensor_data.py           # Sensor data endpoint tests
â”œâ”€â”€ .env                              # Environment variables (not in git)
â”œâ”€â”€ .env.example                      # Environment variables template
â”œâ”€â”€ .gitignore                        # Git ignore rules
â”œâ”€â”€ alembic.ini                       # Alembic configuration
â”œâ”€â”€ docker-compose.yml                # Docker Compose configuration
â”œâ”€â”€ Dockerfile                        # Docker image definition
â”œâ”€â”€ pytest.ini                        # Pytest configuration
â”œâ”€â”€ requirements.txt                  # Python dependencies
â””â”€â”€ README.md                         # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- Python 3.11+ (for local development)

### Running with Docker (Recommended)

1. Clone the repository:
```bash
git clone https://github.com/edvinbehdadi/FastAPI-Backend-Challenge-CRUD.git
cd FastAPI-Backend-Challenge-CRUD
```

2. Create environment file:
```bash
cp .env.example .env
# Edit .env if needed (default values work with Docker)
```

3. Start the application:
```bash
docker-compose up --build
```

4. The API will be available at:
   - **API**: http://localhost:8000
   - **Interactive docs (Swagger)**: http://localhost:8000/docs
   - **Alternative docs (ReDoc)**: http://localhost:8000/redoc
   - **OpenAPI Schema**: http://localhost:8000/openapi.json

**Note:** On first startup, the application will automatically:
- Create database tables via Alembic migrations
- Initialize sample data (units, sensors, and sensor readings)

To reset and reinitialize data:
```bash
docker-compose down -v
docker-compose up --build
```

### Running Locally (without Docker)

1. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Install and setup PostgreSQL:
```bash
# Install PostgreSQL
sudo apt update
sudo apt install postgresql postgresql-contrib

# Start PostgreSQL service
sudo systemctl start postgresql
sudo systemctl enable postgresql

# Create database and user
sudo -u postgres psql

# In PostgreSQL shell:
CREATE DATABASE iot_sensors;
CREATE USER iot_user WITH PASSWORD 'your_password';
ALTER DATABASE iot_sensors OWNER TO iot_user;
ALTER SCHEMA public OWNER TO iot_user;
GRANT ALL PRIVILEGES ON DATABASE iot_sensors TO iot_user;
\q
```

4. Configure environment variables:
```bash
cp .env.example .env
# Edit .env with your database credentials:
# DATABASE_HOST=localhost
# DATABASE_USER=iot_user
# DATABASE_PASSWORD=your_password
```

5. Run database migrations:
```bash
alembic upgrade head
```

6. Initialize sample data (optional):
```bash
python scripts/init_sample_data.py
```

7. Start the application:
```bash
uvicorn app.main:app --reload
```

## ğŸ“Š Database Schema

### Units Table
Physical locations or organizational units where sensors are deployed.

```sql
CREATE TABLE units (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    location VARCHAR(500) NOT NULL,
    description TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**Purpose**: Represent facilities like factories, warehouses, or buildings.

### Sensors Table
IoT sensors attached to units for data collection.

```sql
CREATE TYPE sensor_type_enum AS ENUM (
    'temperature', 'humidity', 'pressure', 
    'motion', 'light', 'sound'
);

CREATE TYPE sensor_status_enum AS ENUM (
    'active', 'inactive', 'maintenance'
);

CREATE TABLE sensors (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    sensor_type sensor_type_enum NOT NULL,
    unit_id INTEGER NOT NULL REFERENCES units(id) ON DELETE CASCADE,
    status sensor_status_enum NOT NULL DEFAULT 'active',
    description TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**Purpose**: Track individual sensors and their operational status.

### Sensor Data Table
Data readings collected from sensors.

```sql
CREATE TYPE data_status_enum AS ENUM (
    'pending', 'validated', 'archived', 'invalid'
);

CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INTEGER NOT NULL REFERENCES sensors(id) ON DELETE CASCADE,
    value DOUBLE PRECISION NOT NULL,
    unit VARCHAR(50),
    status data_status_enum NOT NULL DEFAULT 'pending',
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**Purpose**: Store time-series data from sensors with validation workflow.

## ğŸ”Œ API Endpoints

### Units Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/units/` | Create a new unit |
| GET | `/api/units/` | Get all units (paginated) |
| GET | `/api/units/{id}` | Get unit by ID |
| PUT | `/api/units/{id}` | Update unit |
| DELETE | `/api/units/{id}` | Delete unit (cascades to sensors and data) |
| GET | `/api/units/{id}/statistics` | Get unit statistics |

### Sensors Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/sensors/` | Create a new sensor |
| GET | `/api/sensors/` | Get all sensors (filter by unit_id) |
| GET | `/api/sensors/{id}` | Get sensor by ID |
| PUT | `/api/sensors/{id}` | Update sensor |
| DELETE | `/api/sensors/{id}` | Delete sensor (cascades to data) |

### Sensor Data Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/sensor-data/` | Create new sensor data |
| GET | `/api/sensor-data/` | Get all sensor data (filter by sensor_id, status) |
| GET | `/api/sensor-data/{id}` | Get sensor data by ID |
| PUT | `/api/sensor-data/{id}` | Update sensor data |
| PUT | `/api/sensor-data/{id}/validate` | Mark data as validated |
| PUT | `/api/sensor-data/{id}/archive` | Mark data as archived |
| DELETE | `/api/sensor-data/{id}` | Delete sensor data |

## ğŸ“š API Documentation (OpenAPI)

This API is fully documented using **OpenAPI 3.0** specification with comprehensive examples and descriptions.

### Accessing Documentation:

1. **Swagger UI** (Interactive): http://localhost:8000/docs
   - Try out API calls directly from the browser
   - See request/response examples for all endpoints
   - Test different scenarios with pre-filled examples
   - View all schemas and models with descriptions

2. **ReDoc** (Alternative): http://localhost:8000/redoc
   - Clean, readable documentation
   - Better for reading and understanding API structure
   - Detailed descriptions and examples
   - Mobile-friendly interface

3. **OpenAPI JSON**: http://localhost:8000/openapi.json
   - Raw OpenAPI specification
   - Import into Postman, Insomnia, or other tools
   - Generate client SDKs in any language

### Documentation Features:

- âœ… Comprehensive endpoint descriptions
- âœ… Request/response schemas with examples
- âœ… HTTP status codes documentation (200, 201, 404, 422, 500)
- âœ… Parameter descriptions and validation rules
- âœ… Model schemas with field descriptions
- âœ… Enum values and their meanings
- âœ… Interactive testing capability
- âœ… Error response examples

### Using Swagger UI:

1. Navigate to http://localhost:8000/docs
2. Browse available endpoints organized by tags (units, sensors, sensor-data)
3. Click on any endpoint to expand details
4. Click "Try it out" to test the endpoint
5. Fill in parameters and request body (examples provided)
6. Click "Execute" to send the request
7. View the response with status code and data

### API Examples in Documentation:

Each endpoint includes pre-filled examples:
- **Units**: Factory locations, warehouses, office buildings
- **Sensors**: Temperature, humidity, pressure sensors
- **Sensor Data**: Real-time readings with different statuses

## ğŸ² Sample Data

The application automatically initializes with realistic sample data on first startup.

### What's Included:

- **4 Units**: Different types of facilities
- **Multiple Sensors per Unit**: Various sensor types
- **Time-series Data**: Realistic sensor readings

### Sample Data Details:

**Units:**
- Factory A - Production Floor (Building 1, Floor 2)
- Warehouse B - Storage Area (Building 3, Ground Floor)
- Office Building C (Building 2, All Floors)
- Data Center (Building 4, Basement)

**Sensor Types:**
- **Temperature**: Monitoring ambient temperature (celsius)
- **Humidity**: Monitoring moisture levels (percentage)
- **Pressure**: Monitoring atmospheric pressure (pascal)
- **Motion**: Detecting movement (boolean/count)
- **Light**: Monitoring illumination (lux)
- **Sound**: Monitoring noise levels (decibels)

**Data Status Distribution:**
- Pending: Awaiting validation
- Validated: Confirmed as accurate
- Archived: Historical data

### Sample Data Workflow:

The sample data demonstrates a complete IoT monitoring scenario:

1. **Setup Phase**: Units and sensors are created
2. **Data Collection**: Sensors generate readings
3. **Validation**: Admin reviews and validates data
4. **Archival**: Old validated data is archived

### Reinitializing Sample Data:

```bash
# Stop and remove containers including volumes
docker-compose down -v

# Rebuild and start (will reinitialize data)
docker-compose up --build
```

### Manual Sample Data Initialization:

```bash
# With Docker
docker-compose exec api python scripts/init_sample_data.py

# Locally
python scripts/init_sample_data.py
```

**Note:** The initialization script is idempotent - it checks if data exists and won't duplicate entries.

## ğŸ“ API Usage Examples

### Create a Unit
```bash
curl -X POST "http://localhost:8000/api/units/" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Factory A",
    "location": "Building 1, Floor 2",
    "description": "Main production unit"
  }'
```

**Response:**
```json
{
  "id": 1,
  "name": "Factory A",
  "location": "Building 1, Floor 2",
  "description": "Main production unit",
  "created_at": "2025-01-15T10:30:00Z"
}
```

### Create a Sensor
```bash
curl -X POST "http://localhost:8000/api/sensors/" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Temperature Sensor 1",
    "sensor_type": "temperature",
    "unit_id": 1,
    "status": "active",
    "description": "Monitors room temperature"
  }'
```

**Available Sensor Types:**
- `temperature` - Temperature sensors
- `humidity` - Humidity sensors
- `pressure` - Pressure sensors
- `motion` - Motion detectors
- `light` - Light sensors
- `sound` - Sound level meters

### Create Sensor Data
```bash
curl -X POST "http://localhost:8000/api/sensor-data/" \
  -H "Content-Type: application/json" \
  -d '{
    "sensor_id": 1,
    "value": 23.5,
    "unit": "celsius",
    "status": "pending"
  }'
```

### Validate Sensor Data
```bash
curl -X PUT "http://localhost:8000/api/sensor-data/1/validate" \
  -H "Content-Type: application/json"
```

### Archive Sensor Data
```bash
curl -X PUT "http://localhost:8000/api/sensor-data/1/archive" \
  -H "Content-Type: application/json"
```

### Get Unit Statistics
```bash
curl "http://localhost:8000/api/units/1/statistics"
```

**Response:**
```json
{
  "unit_id": 1,
  "unit_name": "Factory A",
  "total_sensors": 5,
  "active_sensors": 4,
  "inactive_sensors": 1,
  "total_data_points": 1250,
  "latest_data_timestamp": "2025-01-15T14:30:00Z"
}
```

### Get Sensors with Filtering
```bash
# Get all sensors for a specific unit
curl "http://localhost:8000/api/sensors/?unit_id=1"

# Get paginated results
curl "http://localhost:8000/api/sensors/?skip=0&limit=10"
```

### Get Sensor Data with Filtering
```bash
# Get all data for a specific sensor
curl "http://localhost:8000/api/sensor-data/?sensor_id=1"

# Get only validated data
curl "http://localhost:8000/api/sensor-data/?status=validated"

# Get data with sensor and unit details
curl "http://localhost:8000/api/sensor-data/?with_details=true"
```

## ğŸ§ª Running Tests

The project includes comprehensive unit tests covering all endpoints and business logic.

### Test Coverage:

- âœ… Unit CRUD operations
- âœ… Sensor CRUD operations
- âœ… Sensor Data CRUD operations
- âœ… Validation workflow
- âœ… Archive workflow
- âœ… Error handling
- âœ… Edge cases

### Running Tests:

#### With Docker (Recommended):
```bash
# Run all tests
docker-compose exec api pytest

# Run with verbose output
docker-compose exec api pytest -v

# Run specific test file
docker-compose exec api pytest tests/test_units.py

# Run with coverage report
docker-compose exec api pytest --cov=app --cov-report=html
```

#### Locally:
```bash
# Activate virtual environment
source venv/bin/activate

# Run all tests
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/test_units.py

# Run with coverage
pytest --cov=app --cov-report=html

# View coverage report
open htmlcov/index.html  # On macOS
xdg-open htmlcov/index.html  # On Linux
```

### Test Output Example:
```
tests/test_units.py::test_create_unit PASSED           [ 14%]
tests/test_units.py::test_get_unit PASSED              [ 28%]
tests/test_units.py::test_update_unit PASSED           [ 42%]
tests/test_sensors.py::test_create_sensor PASSED       [ 57%]
tests/test_sensor_data.py::test_validate_data PASSED   [ 71%]
...
======================== 38 passed in 2.45s =========================
```

## ğŸ—„ï¸ Database Migrations

The project uses Alembic for database schema management and versioning.

### Common Migration Commands:

```bash
# Create a new migration
alembic revision -m "description of changes"

# Apply all pending migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# View migration history
alembic history

# Check current migration version
alembic current

# Reset to specific version
alembic downgrade <revision_id>
```

### Migration Workflow:

1. **Make Schema Changes**: Modify models or create new ones
2. **Generate Migration**: `alembic revision -m "add_new_field"`
3. **Edit Migration**: Review and modify the generated migration file
4. **Apply Migration**: `alembic upgrade head`
5. **Commit**: Commit the migration file to version control

### Migration Files Location:
```
alembic/versions/xxxx_migration_name.py
```

## ğŸ¯ Architecture & Design Patterns

### Layered Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Layer (FastAPI Routes)   â”‚  â† HTTP requests/responses
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Service Layer                 â”‚  â† Business logic
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Repository Layer              â”‚  â† Data access
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Database (PostgreSQL)         â”‚  â† Data storage
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Repository Pattern

**Purpose**: Abstract data access logic from business logic

**Benefits**:
- Separation of concerns
- Easier testing (can mock repositories)
- Centralized data access
- No ORM dependency

**Implementation**:
```python
class BaseRepository:
    """Base repository with common CRUD operations"""
    async def fetch_one(query, *args)
    async def fetch_all(query, *args)
    async def execute(query, *args)

class UnitRepository(BaseRepository):
    """Specific repository for Unit operations"""
    async def create(unit: UnitCreate)
    async def get_by_id(unit_id: int)
    async def update(unit_id: int, unit: UnitUpdate)
    async def delete(unit_id: int)
```

### Service Layer

**Purpose**: Contain business logic and orchestrate repository calls

**Responsibilities**:
- Validate business rules
- Handle exceptions
- Coordinate multiple repository operations
- Transform data between layers

**Example**:
```python
class UnitService:
    def __init__(self):
        self.repository = UnitRepository()
    
    async def create_unit(self, unit: UnitCreate) -> Unit:
        # Business logic here
        unit_data = await self.repository.create(unit)
        return Unit(**unit_data)
```

### SOLID Principles

**Single Responsibility Principle (SRP)**:
- Each class has one reason to change
- Repositories: data access only
- Services: business logic only
- Routes: HTTP handling only

**Open/Closed Principle (OCP)**:
- Base repository provides common functionality
- Extended without modifying base

**Liskov Substitution Principle (LSP)**:
- All repositories follow the same contract
- Interchangeable implementations

**Interface Segregation Principle (ISP)**:
- Focused interfaces
- No unnecessary methods

**Dependency Inversion Principle (DIP)**:
- High-level modules don't depend on low-level modules
- Both depend on abstractions

### Exception Handling

Custom exceptions for different error scenarios:

```python
NotFoundException       # 404 - Resource not found
BadRequestException     # 400 - Invalid request
ValidationException     # 422 - Validation error
ConflictException      # 409 - Conflict (duplicate, etc.)
DatabaseException      # 500 - Database error
InternalServerException # 500 - Unexpected error
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the project root:

```env
# Database Configuration
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=iot_sensors
DATABASE_USER=iot_user
DATABASE_PASSWORD=your_password_here
```

### Docker Environment

For Docker, the database host is `db` (service name):

```env
DATABASE_HOST=db
DATABASE_PORT=5432
DATABASE_NAME=iot_sensors
DATABASE_USER=iot_user
DATABASE_PASSWORD=1245
```

### Configuration Files

- `.env` - Environment variables (not in git)
- `.env.example` - Template for environment variables
- `alembic.ini` - Alembic configuration
- `pytest.ini` - Pytest configuration
- `docker-compose.yml` - Docker services configuration

## ğŸ“¦ Dependencies

### Core Dependencies:
- **FastAPI** (0.104+): Modern web framework
- **asyncpg**: Async PostgreSQL driver
- **Pydantic** (2.0+): Data validation
- **Uvicorn**: ASGI server
- **python-dotenv**: Environment variables

### Development Dependencies:
- **Alembic**: Database migrations
- **pytest**: Testing framework
- **pytest-asyncio**: Async test support
- **httpx**: HTTP client for testing

### Full Requirements:
See `requirements.txt` for complete list with versions.

## ğŸ³ Docker Configuration

### Services:

**Database (PostgreSQL 15)**:
- Image: `postgres:15-alpine`
- Port: 5432
- Persistent volume for data
- Health checks enabled

**API (FastAPI)**:
- Built from `Dockerfile`
- Port: 8000
- Auto-reload enabled
- Depends on database health

### Docker Commands:

```bash
# Build and start all services
docker-compose up --build

# Start in detached mode
docker-compose up -d

# View logs
docker-compose logs -f

# Stop all services
docker-compose down

# Stop and remove volumes (reset database)
docker-compose down -v

# Execute command in container
docker-compose exec api bash

# Run tests
docker-compose exec api pytest
```

## ğŸ“ˆ Statistics & Monitoring

### Unit Statistics Endpoint

`GET /api/units/{id}/statistics`

Provides comprehensive statistics for a unit:

```json
{
  "unit_id": 1,
  "unit_name": "Factory A",
  "total_sensors": 5,
  "active_sensors": 4,
  "inactive_sensors": 1,
  "maintenance_sensors": 0,
  "total_data_points": 1250,
  "latest_data_timestamp": "2025-01-15T14:30:00Z"
}
```

**Use Cases**:
- Dashboard visualization
- System health monitoring
- Capacity planning
- Performance analysis

## ğŸ”’ Production Considerations

### Security:
- [ ] Add authentication (JWT, OAuth2)
- [ ] Implement authorization (RBAC)
- [ ] Use HTTPS/TLS
- [ ] Add rate limiting
- [ ] Sanitize inputs
- [ ] Use secrets management (AWS Secrets Manager, Vault)
- [ ] Enable CORS properly
- [ ] Add security headers

### Performance:
- [ ] Add Redis caching
- [ ] Optimize database indexes
- [ ] Implement connection pooling limits
- [ ] Add request/response compression
- [ ] Use CDN for static assets
- [ ] Implement pagination everywhere
- [ ] Add query optimization
- [ ] Use database read replicas

### Monitoring:
- [ ] Add structured logging (JSON)
- [ ] Implement health checks (`/health`, `/ready`)
- [ ] Add metrics collection (Prometheus)
- [ ] Set up alerting (PagerDuty, Slack)
- [ ] Add APM (Application Performance Monitoring)
- [ ] Track error rates
- [ ] Monitor response times
- [ ] Log slow queries

### Reliability:
- [ ] Add retry logic with exponential backoff
- [ ] Implement circuit breakers
- [ ] Add request timeouts
- [ ] Set up automated database backups
- [ ] Implement graceful shutdown
- [ ] Add health check endpoints
- [ ] Use blue-green deployments
- [ ] Set up disaster recovery

### DevOps:
- [ ] Set up CI/CD pipeline
- [ ] Automate testing
- [ ] Container orchestration (Kubernetes)
- [ ] Infrastructure as Code (Terraform)
- [ ] Automated scaling
- [ ] Log aggregation (ELK, Splunk)
- [ ] Secret rotation
- [ ] Automated rollbacks

## ğŸ› Troubleshooting

### Common Issues:

#### 1. PostgreSQL Permission Issues

**Error**: `permission denied for schema public`

**Solution**:
```bash
sudo -u postgres psql
\c iot_sensors
ALTER DATABASE iot_sensors OWNER TO iot_user;
ALTER SCHEMA public OWNER TO iot_user;
GRANT ALL ON SCHEMA public TO iot_user;
\q
```

#### 2. Port Already in Use

**Error**: `address already in use`

**Solution**:
```bash
# Find process using port 5432
sudo lsof -i :5432

# Kill the process
sudo kill -9 <PID>

# Or change port in docker-compose.yml
ports:
  - "5433:5432"
```

#### 3. psycopg2 Installation Issues

**Error**: `pg_config executable not found`

**Solution**:
```bash
# Install PostgreSQL development packages
sudo apt install libpq-dev python3-dev

# Or use binary version
pip install psycopg2-binary
```

#### 4. Docker Build Issues

**Error**: `failed to compute cache key`

**Solution**:
```bash
# Clear Docker cache
docker-compose down
docker system prune -a
docker-compose build --no-cache
```

#### 5. Database Connection Issues

**Error**: `could not connect to server`

**Solution**:
```bash
# Check if PostgreSQL is running
sudo systemctl status postgresql

# Start PostgreSQL
sudo systemctl start postgresql

# Test connection
psql -U iot_user -d iot_sensors -h localhost

# Check Docker network
docker network ls
docker network inspect <network_name>
```

#### 6. Migration Issues

**Error**: `target database is not up to date`

**Solution**:
```bash
# Check current version
alembic current

# View history
alembic history

# Stamp current version
alembic stamp head

# Or downgrade and upgrade
alembic downgrade base
alembic upgrade head
```

### Debug Mode:

Enable detailed logging:

```python
# In app/main.py
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Getting Help:

1. Check application logs:
```bash
docker-compose logs api
```

2. Check database logs:
```bash
docker-compose logs db
```

3. Access container shell:
```bash
docker-compose exec api bash
```

## ğŸ“„ License

This project is developed as a technical assessment for recruitment purposes.

## ğŸ‘¨â€ğŸ’» Author

**Developed by:** Edvin â€ŒBehdadi

**Project Type:** FastAPI Backend Challenge - IoT Sensors Management System

**Technologies Used:**
- FastAPI
- PostgreSQL
- asyncpg
- Alembic
- Docker
- pytest

---



**Note**: This is a demonstration project showcasing clean architecture, best practices, and production-ready code structure. All sample data is fictional and for demonstration purposes only.